# 1. 说说你在项目中的redis的应用场景

> Redis支持五大数据类型，分别是String、List、Set、Hash、ZSet。

## 1.1 缓存

> String类型
>
> 例如：热点数据缓存、对象缓存、全页缓存、可以提升热点数据的访问数据。

## 1.2 **数据共享分布式**

> String 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享
>
> 例如：分布式Session

## 1.3 **分布式锁**

> String 类型setnx方法，只有不存在时才能添加成功，返回true
>
> ``` java
> public static boolean getLock(String key) {
>     Long flag = jedis.setnx(key, "1");
>     if (flag == 1) {
>         jedis.expire(key, 10); // 避免死锁
>     }
>     return flag == 1;
> }
> 
> public static void releaseLock(String key) {
>     jedis.del(key);
> }
> ```

## 1.4 全局ID

> int类型，incrby，利用原子性
>
> incrby userid 1000
>
> 分库分表的场景，一次性拿一段

## 1.5 计数器

> int类型，incr方法
>
> 文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库

## 1.6 限流

> int类型，incr方法
>
> 以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false	

# 2. Set、Zset分别用于哪些场景

+ set
  + . 标签:给用户打上感兴趣的标签，然后就能知道相同不同用户拥有相互爱好的群体；
  + 公共好友: 一个人的好友，这样的话就能知道共同拥有的好友；
+ Zset 
  + 根据时间排序的新闻列表等，成绩
  +  [阅读](https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttp%3A%2F%2Fbook.2cto.com%2F)排行榜

# 3. redis是单线程还是多线程

+ 无论什么版本 `工作线程`就是一个
+ 6.x出现了IO多线程
+ 单线程, 满足redis的串行原子。只不过IO多线程后，把输入/输出放到更多的线程里去并行好处如下
  + 执行时间缩短、更快
  + 更好的利用系统以及系统资源

# 4. redis 存在线程安全的问题吗？为什么

单线程串行，redis可以保障内部串行，但是在业务使用上面要自行保障顺序

# 5.遇到过缓存穿透吗？

`穿透`：缓存穿透是指查询一个根本不存在的数据， 缓存层和存储层都不会命中， 通常出于容错的考虑， 如果从存储 层查不到数据则不写入缓存层。

+ 原因：
  + 自身业务代码或者数据出现问题
  + 一些恶意攻击、 爬虫等造成大量空命中。

+ 方法
  + 设置 null key(会造成大量的redis存null key，内存空间浪费)
  + 布隆过滤器(最后的方案)

如果是多个请求一起过来，已经到达的需求已经在串行里， 根据上面的方案，还是会在这个时候查询数据库

这个时候设置一个锁，多个请求去抢一个锁

# 6.遇到过缓存击穿(失效)吗？

由于大批量缓存在`同一时间失效`可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大 甚至挂掉，对于这种情况我们在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同 时间

`击穿`: 热点key 过期(从来没有被缓存的) 数据库有，大量的并发，redis没有缓存

`方法`：每个key设置随机的过期时间

并发的问题就是要使用锁

+ 请求redis，看是否有
+ 所有的请求进行抢锁
  + 抢到的查询Db O(1)
  + 没有抢到的sleep
+ 获取Db数据更新redis
+ sleep回到第一步 

# 7.如何避免缓存雪崩

缓存集中在一段时间内失效，引发大量缓存穿透，所有的查询都落在数据库上，造成[缓存雪崩](https://so.csdn.net/so/search?q=缓存雪崩&spm=1001.2101.3001.7020)，由于原有缓存失效，新缓存未到期间所有原本访问缓存的都去访问了数据库，而对数据库cpu和内存造成巨大压力，从而引发宕机

预防和解决缓存雪崩问题， 可以从以下三个方面进行着手。

+  保证缓存层服务高可用性，比如使用Redis Sentinel或Redis Cluster。
+ 依赖隔离组件为后端限流熔断并降级。比如使用Sentinel或Hystrix限流降级组件。
+ 提前演练。可以在双十一的时候，就行文件的备份，将文件(aof、rdb)cp到另个redis里面去

2.1 加锁排队

mutex互斥锁解决，Redis的setnx去set一个mutex key,当操作返回成功时，再进行load db并回设到缓存，否则就重试整个get缓存的方法。

2.2 数据预热

数据预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候先查询数据库。

2.3 双层缓存策略

C1为原始缓存，C2为拷贝缓存，C1失效时可以访问C2，C1缓存失效时间设置为短期，C2缓存失效时间设置为长期。

2.4 定时更新缓存策略

失效性要求不高的缓存，容器启动初始化加载，采用定时任务更新或移除缓存。

2.5 缓存失效时间分布均匀

设置不同的过期时间，让缓存失效的时间尽量分布均匀。

# 8.缓存如何回收的

> + 后台轮询，分段分批的删除过期的key
> + 请求的时候判断是否已经过期

# 9.redis是怎么删除过期的key



# 10.缓存如何淘汰的

内存空间不足的情况下，会进行淘汰

+ lru/lfu/random
+ 全空间
+ 设置过 过期的集合中

# 9.如何进行缓存预热

> + 开发逻辑上面也要规避差集，会造成击穿，穿透，雪崩
>
> + 解决方案
>
>   1）直接写个缓存刷新页面，上线时手工操作下。
>   2）数据量不大，可以在项目启动的时候自动进行加载。
>   3）定时刷新缓存。

# 10.数据库与缓存不一致如何解决

## 10.1 **先删除缓存，再更新数据库**

![image-20220702112154873](https://cdn.wuzx.cool/image-20220702112154873.png)

> 假设线程A删除缓存的值后，还没有来得及更新数据库(比如说网络延迟)，线程B开始读取数据，这个时候B会发现缓存缺失，就只能去数据库中读取，这会带来两个问题
>
> + 线程B读取到数据库中的旧值
> + 线程B在缓存缺失的情况下读取数据库，然后将旧值放入缓存，其他的线程也会读取到旧值。此时线程A更新完数据库的值。造成了缓存与数据库不一致

### 解决方案：延迟双删，A线程先删除数据库的数据，**线程A更新完数据库值以后**,**先sleep一小段时间，再进行一次缓存删除操作**（这个时间怎么确定呢？建议你在业务程序运行的时候，统计下线程读数据和写缓存的操作时间，以此为基础来进行估算。）---但是会性能下降

## 10.2 **先更新数据库值，再删除缓存值。**

![image-20220702114040929](https://cdn.wuzx.cool/image-20220702114040929.png)

> 解决方案:
>
> - 删除缓存值或更新数据库失败而导致数据不一致，你可以使用重试机制确保删除或更新操作成功。
> - 在删除缓存值、更新数据库的这两步操作中，有其他线程的并发读操作，导致其他线程读取到旧值，应对方案是延迟双删

![image-20220702114218297](https://cdn.wuzx.cool/image-20220702114218297.png)

### 10.3 使用 Binlog 和 Canal 从 MySQL 抽取数据

​	![image-20220725231044889](https://cdn.wuzx.cool/image-20220725231044889.png)

Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用

# 11.简述一下主从不一致的问题

> Redis 的确是弱一致性，异步的同步
>
> Redis 锁不能用主从（单实例、分片集群、redlock）
>
> 在配置中提供必须多少个Client连接可以同步，你可以配置同步因子，趋于强一致性

# 12.Redis有哪些持久化方法

+ RDB:是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。
+ AOF:以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。
+ 主从同步 psync

# 13.Redis也打不住了，万级流量打到DB上，该怎么处理

456

# 14. 描述一下redis持久化原理

当前线程阻塞服务

异步后台进程完成持久化

Fork + cow

# 15.为什么使用setNx

原子性

set if not exist
当某个key不存在的时候创建这个key并设置value，当它存在的话就不进行操作。
set if exist
当某个key存在的时候才会设置成功。

# 16.分布式锁(可以写入项目中)

## 1.1 Setnx key value expire time

```  shell
setnx key value ex 10 
// 必须设置过期时间,不然如果服务过了，其他的将永远获取不到锁
```

+ setnx key value ex 10 `·必须原子操作`·，如果拆分，当key设置成功，然后执行expire 的时候，redis宕机，可能过期时间没有设置，所以就会一只造成死锁

+ 如果事务还没有处理完，锁过期了，那么别人是可以获取到锁的，然后你会进行删除别人的锁的操作

  + 就是生成一个uuid,value设置这个uuid,然后哦，最后面删除key的时候判断 uuid 是相同的才删除(这样还是会有问题不推荐这么做)

    ``` java
    if (clientId.equals(stringRedisTemplate.opsForValue().get(lockKey))) {
      stringRedisTemplate.delete(lockKey);
    }
    ```

    

  + 起一个线程续期，使得锁不会过期

    + 使用Redission

      原理![Redisson分布式锁原理](https://cdn.wuzx.cool/Redisson%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%8E%9F%E7%90%86.png)

      ``` java
        //获取锁对象
              RLock redissonLock = redisson.getLock(lockKey);
              //加分布式锁
              redissonLock.lock();  //  .setIfAbsent(lockKey, clientId, 30, TimeUnit.SECONDS);
              try {
                      System.out.println("扣减失败，库存不足");
              } finally {
                  //解锁
                  redissonLock.unlock();
              }
      ```

## 1.2 分段锁

key : product:100_1 100

![image-20220714012041496](https://cdn.wuzx.cool/image-20220714012041496.png)

> 主从集群问题 ，服务A获取到锁，master 挂了，此时数据还没有同步到slave节点，然后服务A1进行枷锁，还是可以获得锁
>
> ![image-20220714012918498](https://cdn.wuzx.cool/image-20220714012918498.png)
>
> ## 解决方法：红锁
>
> + 准备5台没有关系的redis服务，全是主
> + 先在1加锁，2加锁，3加锁，过半就是加锁成功
> + 然后服务A2准备加锁，1,2,3加锁失败，只能4,5加锁成功，但是没有过半，加锁失败

## 红锁的缺点，如果中间redis重启，数据丢失，所以其他的线程可以加锁	（延迟启动24h）

![image-20220714014010000](https://cdn.wuzx.cool/image-20220714014010000.png)

## gc （stop the world ,续期线程没有执行,所以两个线程都获取到了锁）

> 鸵鸟算法

# 17、冷热数据分离

## 1.简单方案数据冷热分离

> + 创建商品的时候就将数据存入redis中，并设置超时时间，例如1h，1d
> + 修改商品的时候，同时修改redis,设置超时时间
> + 查询的时候，查询这个数据，续约这个key `redis.expire(key,time,unit)`

# 18.热点缓存key重建优化

> 开发人员使用“缓存+过期时间”的策略既可以加速数据读写， 又保证数据的定期更新， 这种模式基本能够满 足绝大部分需求。 但是有两个问题如果同时出现， 可能就会对应用造成致命的危害:
>
> + 当前key是一个热点key(例如一个热门的娱乐新闻)，并发量非常大。
>
> + 重建缓存不能在短时间完成， 可能是一个复杂计算， 例如复杂的SQL、 多次IO、 多个依赖等。 在缓存失效的瞬间， 有大量线程来重建缓存， 造成后端负载加大， 甚至可能会让应用崩溃。 要解决这个问题主要就是要避免大量线程同时重建缓存。
>
>   
>
>    我们可以利用互斥锁来解决，此方法只允许一个线程重建缓存， 其他线程等待重建缓存的线程执行完， 重新从 缓存获取数据即可。

``` java

String get(Stringkey){
// 从Redis中获取数据
String value = redis.get(key); // 如果value为空， 则开始重构缓存 
  if (value == null) {
// 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex String mutexKey = "mutext:key:" + key;
if (redis.set(mutexKey, "1", "ex 180", "nx")) { // 从数据源获取数据
value = db.get(key);
// 回写Redis， 并设置过期时间 redis.setex(key, timeout, value); // 删除key_mutex redis.delete(mutexKey);
}// 其他线程休息50毫秒后重试
else {
Thread.sleep(50);
get(key);
}
}
return value;
}
```

# 19.bigkey

> 在Redis中，一个字符串最大512MB，一个二级数据结构(例如hash、list、set、zset)可以存 储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，我就会认为它是bigkey
>
> 1. 字符串类型:它的big体现在单个value值很大，一般认为超过10KB就是bigkey。
>
> 2. 非字符串类型:哈希、列表、集合、有序集合，它们的big体现在元素个数太多。
> 3. 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注 意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造 成阻塞)

## bigkey的危害:

1. 导致redis阻塞

2. 网络拥塞

   > bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问 量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务 器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey 可能会对其他实例也造成影响，其后果不堪设想。

3. 过期删除

   > 有个bigkey，它安分守己(只执行简单的命令，例如hget、lpop、zscore等)，但它设置了过 期时间，当它过期后，会被删除，如果没有使用Redis 4.0的过期异步删除(lazyfree-lazy- expire yes)，就会存在阻塞Redis的可能性。

## bigkey的产生: 一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的，来看几 个例子:

+ (1) 社交类:粉丝列表，如果某些明星或者大v不精心设计下，必是bigkey。
+  (2) 统计类:例如按天存储某项功能或者网站的用户集合，除非没几个人用，否则必是bigkey。
+  (3) 缓存类:将数据从数据库load出来序列化放到Redis里，这个方式非常常用，但有两个地方需 要注意，第一，是不是有必要把所有字段都缓存;第二，有没有相关关联的数据，有的同学为了 图方便把相关数据都存一个key下，产生bigkey。

## 如何优化bigkey

### 1. 拆

> big list: list1、list2、...listN
>  big hash:可以讲数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成 200个key，每个key下面存放5000个用户数据

###  2. 如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要 hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。

### 3.【推荐】:控制key的生命周期，redis不是垃圾桶。

建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)。

# 20.Redis对于过期键有三种清除策略

> + 被动删除，当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期 key
>
> + 主动删除:  由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一 批已过期的key
>
> + 当前已用内存超过maxmemory限定时，会触发主动删除
>
>   `主动删除策略`在redis 4.0之前一共实现了6种内存淘汰策略，在4.0之后，又增加了2种

## a) 针对设置了过期时间的key做处理:

1. volatile-ttl:在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删 除，越早过期的越先被删除
2. volatile-random:就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。
3. volatile-lru:会使用 LRU 算法筛选设置了过期时间的键值对删除。
4. volatile-lfu:会使用 LFU 算法筛选设置了过期时间的键值对删除。


## b) 针对所有的key做处理:

5. allkeys-random:从所有键值对中随机选择并删除数据。
6. allkeys-lru:使用 LRU 算法在所有数据中进行筛选删除。 
7. allkeys-lfu:使用 LFU 算法在所有数据中进行筛选删除。

## c) 不处理:

8. noeviction:不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。

`LRU 算法(Least Recently Used，最近最少使用)` 淘汰很久没被访问过的数据，以最近一次访问时间作为参考。

`LFU 算法(Least Frequently Used，最不经常使用) `淘汰最近一段时间被访问次数最少的数据，以次数作为参考。

> 当存在热点数据时，虽然LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下 降，缓存污染情况比较严重。这时使用LFU可能更好点。
